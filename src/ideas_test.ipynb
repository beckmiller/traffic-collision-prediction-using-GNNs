{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_networkx\n",
    "from sklearn.cluster import DBSCAN\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "import scipy.stats\n",
    "\n",
    "def load_and_analyze_graph(path):\n",
    "    \"\"\"\n",
    "    Load and perform comprehensive analysis on traffic collision graph\n",
    "    \"\"\"\n",
    "    # Load the PyTorch geometric graph\n",
    "    graph = torch.load(path)\n",
    "    \n",
    "    # Convert to NetworkX for certain analyses\n",
    "    G = to_networkx(graph, to_undirected=True)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 1. Network Topology Analysis\n",
    "    results['network_metrics'] = analyze_network_topology(G)\n",
    "    \n",
    "    # 2. Environmental Analysis\n",
    "    results['environmental'] = analyze_environmental_factors(graph)\n",
    "    \n",
    "    # 3. Road Analysis\n",
    "    results['road_analysis'] = analyze_road_characteristics(graph)\n",
    "    \n",
    "    # 4. Spatial Analysis\n",
    "    results['spatial'] = analyze_spatial_patterns(graph)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_network_topology(G):\n",
    "    \"\"\"\n",
    "    Analyze network topology metrics\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'betweenness_centrality': nx.betweenness_centrality(G),\n",
    "        'degree_centrality': nx.degree_centrality(G),\n",
    "        'clustering_coefficient': nx.average_clustering(G),\n",
    "        'average_shortest_path': nx.average_shortest_path_length(G),\n",
    "        'high_risk_nodes': identify_high_risk_nodes(G)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def analyze_environmental_factors(graph):\n",
    "    \"\"\"\n",
    "    Analyze weather-related patterns\n",
    "    \"\"\"\n",
    "    weather_features = ['tavg', 'tmax', 'tmin', 'prcp', 'wspd', 'pres']\n",
    "    \n",
    "    correlations = {}\n",
    "    for feature in weather_features:\n",
    "        if hasattr(graph, feature):\n",
    "            feature_data = getattr(graph, feature)\n",
    "            correlations[feature] = analyze_weather_correlation(feature_data, graph.collision_count)\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "def analyze_road_characteristics(graph):\n",
    "    \"\"\"\n",
    "    Analyze road-specific patterns\n",
    "    \"\"\"\n",
    "    road_stats = {\n",
    "        'one_way_analysis': analyze_one_way_roads(graph),\n",
    "        'road_type_analysis': analyze_road_types(graph),\n",
    "        'traffic_volume_impact': analyze_traffic_volume(graph)\n",
    "    }\n",
    "    return road_stats\n",
    "\n",
    "def analyze_spatial_patterns(graph):\n",
    "    \"\"\"\n",
    "    Perform spatial analysis\n",
    "    \"\"\"\n",
    "    # Extract coordinates\n",
    "    coords = np.column_stack((graph.lat, graph.long))\n",
    "    \n",
    "    # Perform DBSCAN clustering\n",
    "    clustering = DBSCAN(eps=0.1, min_samples=5).fit(coords)\n",
    "    \n",
    "    spatial_analysis = {\n",
    "        'hotspots': identify_hotspots(coords, clustering.labels_),\n",
    "        'spatial_autocorrelation': calculate_spatial_autocorrelation(coords, graph.collision_count)\n",
    "    }\n",
    "    return spatial_analysis\n",
    "\n",
    "def identify_hotspots(coords, cluster_labels):\n",
    "    \"\"\"\n",
    "    Identify collision hotspots based on DBSCAN clustering\n",
    "    \"\"\"\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    hotspots = []\n",
    "    \n",
    "    for cluster in unique_clusters:\n",
    "        if cluster != -1:  # -1 represents noise in DBSCAN\n",
    "            cluster_points = coords[cluster_labels == cluster]\n",
    "            center = np.mean(cluster_points, axis=0)\n",
    "            density = len(cluster_points)\n",
    "            hotspots.append({\n",
    "                'center': center,\n",
    "                'density': density,\n",
    "                'points': cluster_points\n",
    "            })\n",
    "    \n",
    "    return sorted(hotspots, key=lambda x: x['density'], reverse=True)\n",
    "\n",
    "def calculate_spatial_autocorrelation(coords, collision_counts):\n",
    "    \"\"\"\n",
    "    Calculate Moran's I spatial autocorrelation\n",
    "    \"\"\"\n",
    "    # Calculate distance matrix\n",
    "    dist_matrix = cdist(coords, coords)\n",
    "    \n",
    "    # Convert to weights matrix (inverse distance)\n",
    "    weights = 1 / (dist_matrix + np.eye(len(coords)))  # Add eye to avoid division by zero\n",
    "    weights[weights == np.inf] = 0\n",
    "    \n",
    "    # Normalize weights\n",
    "    weights = weights / weights.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Calculate Moran's I\n",
    "    return moran(collision_counts, weights)[0]\n",
    "\n",
    "def analyze_road_types(graph):\n",
    "    \"\"\"\n",
    "    Analyze collision patterns by road type\n",
    "    \"\"\"\n",
    "    road_types = graph.road_type.unique()\n",
    "    analysis = {}\n",
    "    \n",
    "    for road_type in road_types:\n",
    "        mask = graph.road_type == road_type\n",
    "        analysis[road_type] = {\n",
    "            'collision_count': graph.collision_count[mask].sum(),\n",
    "            'collision_rate': graph.collision_count[mask].mean(),\n",
    "            'avg_traffic': graph.aadt[mask].mean() if hasattr(graph, 'aadt') else None\n",
    "        }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def analyze_traffic_volume(graph):\n",
    "    \"\"\"\n",
    "    Analyze relationship between traffic volume and collisions\n",
    "    \"\"\"\n",
    "    if not hasattr(graph, 'aadt'):\n",
    "        return None\n",
    "    \n",
    "    # Calculate correlation between AADT and collisions\n",
    "    correlation = np.corrcoef(graph.aadt, graph.collision_count)[0,1]\n",
    "    \n",
    "    # Bin traffic volumes and calculate average collision rates\n",
    "    bins = np.percentile(graph.aadt, np.linspace(0, 100, 11))\n",
    "    traffic_bins = np.digitize(graph.aadt, bins)\n",
    "    \n",
    "    avg_collisions = [graph.collision_count[traffic_bins == i].mean() \n",
    "                     for i in range(1, len(bins))]\n",
    "    \n",
    "    return {\n",
    "        'correlation': correlation,\n",
    "        'binned_analysis': {\n",
    "            'bins': bins,\n",
    "            'avg_collisions': avg_collisions\n",
    "        }\n",
    "    }\n",
    "\n",
    "def calculate_collision_rate(graph, one_way):\n",
    "    \"\"\"\n",
    "    Calculate collision rate for specific road type\n",
    "    \"\"\"\n",
    "    mask = graph.one_way == one_way\n",
    "    total_collisions = graph.collision_count[mask].sum()\n",
    "    total_roads = mask.sum()\n",
    "    \n",
    "    return {\n",
    "        'total_collisions': total_collisions,\n",
    "        'total_roads': total_roads,\n",
    "        'collision_rate': total_collisions / total_roads if total_roads > 0 else 0\n",
    "    }\n",
    "\n",
    "def plot_weather_correlations(environmental_results, ax):\n",
    "    \"\"\"\n",
    "    Plot weather correlations with collision rates\n",
    "    \"\"\"\n",
    "    features = list(environmental_results.keys())\n",
    "    correlations = list(environmental_results.values())\n",
    "    \n",
    "    sns.barplot(x=features, y=correlations, ax=ax)\n",
    "    ax.set_title('Weather Correlations with Collision Rates')\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "    ax.set_ylabel('Correlation Coefficient')\n",
    "\n",
    "def plot_road_type_analysis(road_analysis, ax):\n",
    "    \"\"\"\n",
    "    Plot collision rates by road type\n",
    "    \"\"\"\n",
    "    road_types = list(road_analysis['road_type_analysis'].keys())\n",
    "    collision_rates = [data['collision_rate'] \n",
    "                      for data in road_analysis['road_type_analysis'].values()]\n",
    "    \n",
    "    sns.barplot(x=road_types, y=collision_rates, ax=ax)\n",
    "    ax.set_title('Collision Rates by Road Type')\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "    ax.set_ylabel('Collision Rate')\n",
    "\n",
    "def plot_spatial_hotspots(spatial_results, lat, long, ax):\n",
    "    \"\"\"\n",
    "    Plot spatial hotspots on a map\n",
    "    \"\"\"\n",
    "    # Create scatter plot of all points\n",
    "    ax.scatter(long, lat, alpha=0.1, c='gray', s=1)\n",
    "    \n",
    "    # Plot hotspots\n",
    "    for hotspot in spatial_results['hotspots']:\n",
    "        ax.scatter(hotspot['center'][1], hotspot['center'][0], \n",
    "                  c='red', s=100, alpha=0.6)\n",
    "        \n",
    "    ax.set_title('Collision Hotspots')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "\n",
    "def visualize_results(results, graph):\n",
    "    \"\"\"\n",
    "    Create visualizations for analysis results\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "    \n",
    "    # 1. Network topology heatmap\n",
    "    sns.heatmap(pd.DataFrame(results['network_metrics']).corr(), \n",
    "                ax=axes[0,0], cmap='coolwarm')\n",
    "    axes[0,0].set_title('Network Metrics Correlation')\n",
    "    \n",
    "    # 2. Weather correlation plot\n",
    "    plot_weather_correlations(results['environmental'], ax=axes[0,1])\n",
    "    \n",
    "    # 3. Road type analysis\n",
    "    plot_road_type_analysis(results['road_analysis'], ax=axes[1,0])\n",
    "    \n",
    "    # 4. Spatial hotspot map\n",
    "    plot_spatial_hotspots(results['spatial'], graph.lat, graph.long, ax=axes[1,1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_networkx\n",
    "from sklearn.cluster import DBSCAN\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sq/1nt0kg2x37j377lq7nqlpz4c0000gn/T/ipykernel_25021/1933452329.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph = torch.load('/Users/beck/Documents/GitHub/ML4RoadSafety/ml_for_road_safety/data/CA/adj_matrix.pt')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/beck/Documents/GitHub/ML4RoadSafety/ml_for_road_safety/data/CA/adj_matrix.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mLoad and perform comprehensive analysis on traffic collision graph\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the PyTorch geometric graph\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/beck/Documents/GitHub/ML4RoadSafety/ml_for_road_safety/data/CA/adj_matrix.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Convert to NetworkX for certain analyses\u001b[39;00m\n\u001b[1;32m      8\u001b[0m G \u001b[38;5;241m=\u001b[39m to_networkx(graph, to_undirected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/cs470/lib/python3.12/site-packages/torch/serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/cs470/lib/python3.12/site-packages/torch/serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/cs470/lib/python3.12/site-packages/torch/serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/beck/Documents/GitHub/ML4RoadSafety/ml_for_road_safety/data/CA/adj_matrix.pt'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load and perform comprehensive analysis on traffic collision graph\n",
    "\"\"\"\n",
    "# Load the PyTorch geometric graph\n",
    "graph = torch.load('/Users/beck/Documents/GitHub/ML4RoadSafety/ml_for_road_safety/data/CA/adj_matrix.pt')\n",
    "\n",
    "# Convert to NetworkX for certain analyses\n",
    "G = to_networkx(graph, to_undirected=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
