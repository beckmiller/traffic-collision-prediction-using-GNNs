{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--------------- Importing Libraries -------------#\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from os.path import dirname\n",
    "\n",
    "from torch.sparse import FloatTensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "#--------------- Initializing Paramaters ----------#\n",
    "\n",
    "path = dirname(os.getcwd())\n",
    "\n",
    "state_name = \"MA\"\n",
    "\n",
    "\n",
    "#---------------- Functions -------------------#\n",
    "\n",
    "\n",
    "def create_edge_features(df_nodes, df_edges):\n",
    "\n",
    "    # Get the number of nodes in the graph\n",
    "    num_nodes = len(df_nodes)\n",
    "\n",
    "    # Initialize a dictionary to store the values, row indices, and column indices for the sparse tensor\n",
    "    values_dict = {f: [] for f in df_edges.columns[2:]}\n",
    "    row_indices_dict = {f: [] for f in df_edges.columns[2:]}\n",
    "    col_indices_dict = {f: [] for f in df_edges.columns[2:]}\n",
    "\n",
    "    # Iterate over each edge in the DataFrame and store its feature values in the dictionary\n",
    "    for i, e in tqdm(df_edges.iterrows(), total=len(df_edges)):\n",
    "        # Get the row and column indices for the sparse tensor\n",
    "        row_idx = e['node_1']\n",
    "        col_idx = e['node_2']\n",
    "\n",
    "        # Get the indices of the row and column nodes in the node DataFrame\n",
    "        row_node_idx = df_nodes[df_nodes['node_id'] == row_idx].index[0]\n",
    "        col_node_idx = df_nodes[df_nodes['node_id'] == col_idx].index[0]\n",
    "\n",
    "        # Store the feature values, row indices, and column indices in the dictionary\n",
    "        for f in df_edges.columns[2:]:\n",
    "            values_dict[f].append(e[f])\n",
    "            row_indices_dict[f].append(row_node_idx)\n",
    "            col_indices_dict[f].append(col_node_idx)\n",
    "\n",
    "    # Create a sparse tensor for each edge feature\n",
    "    edge_features = {}\n",
    "    for f in tqdm(df_edges.columns[2:], total=len(df_edges.columns)-2):\n",
    "        values = torch.FloatTensor(values_dict[f])\n",
    "        row_indices = torch.LongTensor(row_indices_dict[f])\n",
    "        col_indices = torch.LongTensor(col_indices_dict[f])\n",
    "        edge_features[f] = torch.sparse.FloatTensor(\n",
    "            torch.stack([row_indices, col_indices]),\n",
    "            values,\n",
    "            torch.Size([num_nodes, num_nodes])\n",
    "        )\n",
    "\n",
    "    return edge_features\n",
    "\n",
    "\n",
    "def create_adjacency_matrix(df_nodes, df_edges):\n",
    "    # Get the number of nodes in the graph\n",
    "    num_nodes = len(df_nodes)\n",
    "    \n",
    "    # Create a dictionary to map node names to indices\n",
    "    node_indices = {}\n",
    "    for i, node in df_nodes.iterrows():\n",
    "        node_indices[node['node_id']] = i\n",
    "\n",
    "    # Initialize a dictionary to store the values, row indices, and column indices for the sparse tensor\n",
    "    values_dict = {\"weight\": []}\n",
    "    row_indices_dict = {\"weight\": []}\n",
    "    col_indices_dict = {\"weight\": []}\n",
    "\n",
    "    # Iterate over each edge in the DataFrame and store its weight in the dictionary\n",
    "    for i, e in tqdm(df_edges.iterrows(), total=len(df_edges)):\n",
    "        # Get the row and column indices for the sparse tensor\n",
    "        row_idx = node_indices[e[\"node_1\"]]\n",
    "        col_idx = node_indices[e[\"node_2\"]]\n",
    "\n",
    "        # Store the weight, row indices, and column indices in the dictionary\n",
    "        values_dict[\"weight\"].append(e[\"length\"])\n",
    "        row_indices_dict[\"weight\"].append(row_idx)\n",
    "        col_indices_dict[\"weight\"].append(col_idx)\n",
    "        if(e[\"oneway\"]==0):\n",
    "            values_dict[\"weight\"].append(e[\"length\"])\n",
    "            row_indices_dict[\"weight\"].append(col_idx)\n",
    "            col_indices_dict[\"weight\"].append(row_idx)\n",
    "\n",
    "\n",
    "    # Create a sparse tensor for the adjacency matrix\n",
    "    values = torch.FloatTensor(values_dict[\"weight\"])\n",
    "    row_indices = torch.LongTensor(row_indices_dict[\"weight\"])\n",
    "    col_indices = torch.LongTensor(col_indices_dict[\"weight\"])\n",
    "    adj_matrix = torch.sparse.FloatTensor(\n",
    "        torch.stack([row_indices, col_indices]),\n",
    "        values,\n",
    "        torch.Size([num_nodes, num_nodes]),\n",
    "    )\n",
    "\n",
    "    return adj_matrix\n",
    "\n",
    "#--------------- Nodes --------------------------#\n",
    "\n",
    "df_nodes = pd.read_csv(path + \"/Road_Networks/\" + state_name + \"/Road_Network_Nodes_\" + state_name + \".csv\", low_memory=False)\n",
    "\n",
    "df_nodes.columns = [\"node_id\",\"lat\",\"lon\"]\n",
    "\n",
    "#--------------- Edges -------------------------#\n",
    "\n",
    "df_edges = pd.read_csv(path + \"/Road_Networks/\" + state_name + \"/Road_Network_Edges_\" + state_name + \".csv\", low_memory=False)\n",
    "\n",
    "df_edges = df_edges.drop([\"name\"],axis=1)\n",
    "\n",
    "print(\"\\nOne Hot Encode Categorical Features\")\n",
    "\n",
    "print(np.unique(df_edges[\"oneway\"]))\n",
    "\n",
    "# Oneway\n",
    "df_edges[\"oneway\"] = df_edges[\"oneway\"].apply(lambda x: int(x))\n",
    "\n",
    "# Highway\n",
    "highway_types = []\n",
    "for highway_type in np.unique(df_edges[\"highway\"]):\n",
    "    if(highway_type[0] == '['):\n",
    "        dummy = \"\".join([char for char in highway_type if char not in [\"[\",\"]\",\"'\"]])\n",
    "        highway_types += dummy.split(\", \")\n",
    "    else:\n",
    "        highway_types += [highway_type]\n",
    "\n",
    "highway_types = list(np.unique(highway_types))\n",
    "print(len(highway_types))\n",
    "\n",
    "for highway_type in highway_types:\n",
    "    df_edges[highway_type] = df_edges[\"highway\"].apply(lambda x: 1 if highway_type in x else 0)\n",
    "\n",
    "df_edges = df_edges.drop(columns=[\"highway\"])\n",
    "\n",
    "#------------------- Accidents ----------------------#\n",
    "print(\"\\nAccident Records\")\n",
    "df_accidents = pd.read_csv(path + \"/Accidents/\" + state_name + \"/Accidents_Nearest_Street_\" + state_name + \".csv\", low_memory=False)\n",
    "\n",
    "df_accidents[\"accident_date\"] = pd.to_datetime(df_accidents[\"accident_date\"])#,format='%Y-%m-%d')\n",
    "\n",
    "df_accidents[\"year\"] = df_accidents[\"accident_date\"].dt.year\n",
    "df_accidents[\"month\"] = df_accidents[\"accident_date\"].dt.month\n",
    "df_accidents[\"day\"] = df_accidents[\"accident_date\"].dt.day\n",
    "\n",
    "df_accidents = df_accidents.sort_values([\"year\",\"month\"],ascending=[True,True])\n",
    "\n",
    "\n",
    "df_accidents = df_accidents.groupby([\"year\",\"month\",\"node_1\",\"node_2\"],as_index=False)[\"acc_count\"].sum()\n",
    "\n",
    "df_accidents[\"node_1_idx\"] = \"\"\n",
    "df_accidents[\"node_2_idx\"] = \"\"\n",
    "for i in tqdm(range(df_accidents.shape[0])):\n",
    "    df_accidents.loc[i,\"node_1_idx\"] = df_nodes[df_nodes['node_id'] == df_accidents.loc[i,\"node_1\"]].index[0]\n",
    "    df_accidents.loc[i,\"node_2_idx\"] = df_nodes[df_nodes['node_id'] == df_accidents.loc[i,\"node_2\"]].index[0]\n",
    "\n",
    "\n",
    "df_accidents.to_csv(path + \"/Accidents/\" + state_name + \"/Accidents_Nearest_Street_\" + state_name + \"_Monthly.csv\",index=False)\n",
    "df_accidents.to_csv(path + \"/Final_Graphs/\" + state_name + \"/Accidents_Nearest_Street_\" + state_name + \"_Monthly.csv\",index=False)\n",
    "\n",
    "\n",
    "#-------------- Set the dates --------------------#\n",
    "\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2023-04-01'\n",
    "\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='M')\n",
    "\n",
    "dates_df = pd.DataFrame({'year': date_range.year,\n",
    "                   'month': date_range.month})\n",
    "                    # 'day': date_range.day})\n",
    "\n",
    "\n",
    "#------------------- Traffic ----------------------#\n",
    "\n",
    "df_traffic = pd.read_csv(path + \"/Traffic_Volume/\" + state_name + \"/\" + state_name + \"_AADT.csv\")\n",
    "\n",
    "#------------------- Weather ----------------------#\n",
    "\n",
    "df_weather = pd.read_csv(path + \"/Weather_Features/\" + state_name + \"/\" + state_name + \"_Weather_Features.csv\")\n",
    "\n",
    "df_weather[\"time\"] = pd.to_datetime(df_weather[\"time\"])\n",
    "\n",
    "df_weather[\"year\"] = df_weather[\"time\"].dt.year\n",
    "df_weather[\"month\"] = df_weather[\"time\"].dt.month\n",
    "\n",
    "df_weather = df_weather.sort_values([\"year\",\"month\"],ascending=[True,True])\n",
    "\n",
    "\n",
    "#------------------- Adjacency Matrix ----------------------#\n",
    "\n",
    "\n",
    "print(\"\\nAdjacency Matrix\")\n",
    "\n",
    "# N*N*F\n",
    "adj_matrix = create_adjacency_matrix(df_nodes, df_edges)\n",
    "torch.save(adj_matrix, path + \"/Final_Graphs/\" + state_name + '/adj_matrix.pt')\n",
    "\n",
    "\n",
    "print(\"\\nCreate Node Features\")\n",
    "for i in tqdm(range(len(dates_df))):\n",
    "\n",
    "    year = dates_df.loc[i,\"year\"]\n",
    "    month = dates_df.loc[i,\"month\"]\n",
    "\n",
    "    # print(f\"\\n******* Date - {year} - {month} ************\")\n",
    "    \n",
    "    weather_filtered_df = df_weather[(df_weather[\"year\"] == year) & (df_weather[\"month\"] == month)]\n",
    "    weather_filtered_df = weather_filtered_df[[\"node_id\",\"tavg\",\"tmin\",\"tmax\",\"prcp\",\"wspd\",\"pres\"]]\n",
    "    \n",
    "    df_nodes_time = pd.merge(df_nodes, weather_filtered_df, on=[\"node_id\"],how=\"left\").drop_duplicates()\n",
    "\n",
    "    df_nodes_time.to_csv(path + \"/Final_Graphs/\" + state_name + \"/Nodes/node_features_\" + str(year) + \"_\" + str(month) + \".csv\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nCreate Edge Features\")\n",
    "\n",
    "\n",
    "edge_features_time = create_edge_features(df_nodes, df_edges)\n",
    "torch.save(edge_features_time, path + \"/Final_Graphs/\" + state_name + '/Edges/edge_features.pt')\n",
    "\n",
    "\n",
    "for year in np.unique(dates_df[\"year\"]):\n",
    "\n",
    "    month = 1\n",
    "\n",
    "    print(f\"\\n******* Date - {year} ************\")\n",
    "\n",
    "    traffic_filtered_df = df_traffic[(df_traffic[\"year\"] == year)].drop(columns=[\"year\"])\n",
    "\n",
    "\n",
    "    df_edges_time = pd.merge(df_edges, traffic_filtered_df, on=[\"node_1\",\"node_2\"],how=\"left\").drop_duplicates()\n",
    "\n",
    "    # N*N*F\n",
    "    edge_features_time = create_edge_features(df_nodes, df_edges_time)\n",
    "    torch.save(edge_features_time, path + \"/Final_Graphs/\" + state_name + '/Edges/edge_features_traffic_' + str(year) + '.pt')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
