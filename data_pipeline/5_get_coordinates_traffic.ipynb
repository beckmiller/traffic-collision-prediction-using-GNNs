{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--------------- Importing Libraries -------------#\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from os.path import dirname\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from lxml import etree\n",
    "import tabula\n",
    "\n",
    "\n",
    "#--------------- Initializing Paramaters ----------#\n",
    "\n",
    "path = dirname(os.getcwd())\n",
    "\n",
    "state_name = \"DE\"\n",
    "\n",
    "\n",
    "\n",
    "#------------------- Functions ------------------------#\n",
    "\n",
    "\n",
    "def get_df(string):\n",
    "\n",
    "    data = {\n",
    "    'Attribute': [],\n",
    "    'Value': []\n",
    "    }\n",
    "\n",
    "    # Extract attribute-value pairs\n",
    "    lines = string.split('\\n')\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('<th>'):\n",
    "            attribute = line.replace('<th>', '').replace('</th>', '')\n",
    "            data['Attribute'].append(attribute)\n",
    "        elif line.startswith('<td>'):\n",
    "            value = line.replace('<td>', '').replace('</td>', '')\n",
    "            data['Value'].append(value)\n",
    "\n",
    "    # Create a dataframe\n",
    "    df = pd.DataFrame(data).T\n",
    "\n",
    "    # Use the first row as column headers\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "\n",
    "    # print(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def extract_table_kmz(path):\n",
    "\n",
    "    kmz = ZipFile(path, 'r')\n",
    "    kml = kmz.open('doc.kml', 'r').read()\n",
    "\n",
    "    doc = etree.fromstring(kml)\n",
    "\n",
    "    # Iterate over elements and extract IDs\n",
    "    id_list = []\n",
    "    for element in doc.iter():\n",
    "        element_id = element.get('id')\n",
    "        if element_id:\n",
    "            id_list.append(element_id)\n",
    "\n",
    "    final_df = pd.DataFrame(columns = ['CURRENT_YEAR', 'ROAD', 'BEG_MP', 'END_MP', 'ROAD_NAME',\n",
    "        'BEG_BREAKPOINT_ID', 'CURRENT_AADT', 'YEAR_LAST_COUNTED'])\n",
    "\n",
    "\n",
    "    for element_id in tqdm(id_list):\n",
    "\n",
    "        # print(\"\\n\",element_id)\n",
    "\n",
    "        # element_id = 'kml_3418'  # ID of the element you want to extract strings from\n",
    "\n",
    "        # Find the element by ID\n",
    "        element = doc.find('.//*[@id=\"{}\"]'.format(element_id))\n",
    "\n",
    "        if element is not None:\n",
    "            # print(\"Element:\", element.tag)\n",
    "            # print(\"Strings:\")\n",
    "            for child in element.iterchildren():\n",
    "                # print(\"***\",child.text)\n",
    "                if child.text and child.text.strip() and (\"<table>\" in child.text):\n",
    "                    # print(\"YESS\")\n",
    "                    df = get_df(child.text.strip())\n",
    "                    final_df = pd.concat([final_df,df])\n",
    "        else:\n",
    "            print(\"\\tElement not found.\")\n",
    "\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_table_pdf(path_pdf):\n",
    "\n",
    "    tables = tabula.read_pdf(path_pdf, pages=\"all\")\n",
    "\n",
    "    final_df = pd.DataFrame(columns = ['Maint_Rd_Number', 'Road_Name', 'End of Section Mileage', \n",
    "                                    'BEG_BREAKPNT_ID','AADT','Year Last Counted','Traffic Group'])\n",
    "\n",
    "\n",
    "    for i in range(len(tables)):\n",
    "        df = tables[i]\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                df.columns = final_df.columns\n",
    "            except:\n",
    "                df = df.drop(df.columns[2],axis=1)\n",
    "                df.columns = final_df.columns\n",
    "\n",
    "            final_df = pd.concat([final_df,df])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    final_df['AADT'] = pd.to_numeric(final_df['AADT'], errors='coerce')\n",
    "    final_df['End of Section Mileage'] = pd.to_numeric(final_df['End of Section Mileage'], errors='coerce')\n",
    "\n",
    "    final_df = final_df[final_df[\"AADT\"].isnull() == False]\n",
    "    final_df = final_df[final_df[\"End of Section Mileage\"].isnull() == False]\n",
    "    final_df = final_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "\n",
    "def click_first_result(driver, address):\n",
    "\n",
    "    wait = WebDriverWait(driver, 5)\n",
    "\n",
    "    # Load the Google Maps page\n",
    "    driver.get('https://www.google.com/maps')\n",
    "\n",
    "    wait.until(EC.element_to_be_clickable((By.ID, \"searchboxinput\"))).send_keys(address)\n",
    "    time.sleep(3)\n",
    "    wait.until(EC.element_to_be_clickable((By.ID, \"searchbox-searchbutton\"))).click()\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "    # Get the updated URL\n",
    "    updated_url = driver.current_url\n",
    "    \n",
    "    return updated_url\n",
    "\n",
    "def concat_files(path, final_file_name):\n",
    "    '''\n",
    "    Combines all files in a directory and saves it in a single file\n",
    "    Parameters:\n",
    "        path (str): directory where all independent files are saved\n",
    "        final_file_name (str): path of the final file\n",
    "    '''\n",
    "    count = 0\n",
    "    for file_name in os.listdir(path):\n",
    "        try:\n",
    "            df = pd.concat([df,pd.read_csv(path + file_name, low_memory=False)])\n",
    "        except:\n",
    "            df = pd.read_csv(path + file_name, low_memory=False)\n",
    "\n",
    "        count += 1\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    df.to_csv(final_file_name,index=False)\n",
    "\n",
    "\n",
    "#----------------------- Generate Files ------------------------#\n",
    "\n",
    "if(state_name == \"MD\"):\n",
    "\n",
    "    df = pd.read_csv(path + \"/MDOT_SHA_Annual_Average_Daily_Traffic_(AADT) (1).csv\")\n",
    "\n",
    "    # df[\"Address\"] = df[\"STATION_DESC\"] + \", \" + df[\"ROAD_SECTION\"] + \", \" + df[\"ROADNAME\"] + \", \" + df[\"COUNTY_DESC\"] + \", Maryland\"\n",
    "\n",
    "    df[\"Address\"] = df[\"ROAD_SECTION\"] + \", \" + df[\"ROADNAME\"] + \", \" + df[\"COUNTY_DESC\"] + \", Maryland\"\n",
    "\n",
    "    df = df[[\"Address\",'AADT_2012',\n",
    "    'AADT_2013',\n",
    "    'AADT_2014',\n",
    "    'AADT_2015',\n",
    "    'AADT_2016',\n",
    "    'AADT_2017',\n",
    "    'AADT_2018',\"AADT\"]]\n",
    "\n",
    "if(state_name == \"DE\"):\n",
    "\n",
    "    final_df = pd.DataFrame(columns = [\"Year\",'Maint_Rd_Number', 'Road_Name', 'End of Section Mileage', \n",
    "                                    'BEG_BREAKPNT_ID','AADT','Year Last Counted','Traffic Group'])\n",
    "\n",
    "\n",
    "    for year in [2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019]:\n",
    "        print(year)\n",
    "\n",
    "        for file_name in os.listdir(path + \"/Traffic_Volume/\" + state_name +  \"/\" + str(year) + \"/\"):\n",
    "\n",
    "            df = extract_table_pdf(path + \"/Traffic_Volume/\" + state_name +  \"/\" + str(year) + \"/\" + file_name)\n",
    "            df[\"Year\"] = year\n",
    "            \n",
    "            final_df = pd.concat([final_df,df])\n",
    "\n",
    "\n",
    "    final_df = final_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    final_df.to_csv(path + \"/Traffic_Volume/\" + state_name + \"/\" + state_name + \"_AADT.csv\")\n",
    "\n",
    "\n",
    "\n",
    "    df = pd.read_csv(path + \"/Traffic_Volume/\" + state_name + \"/\" + state_name + \"_AADT.csv\")\n",
    "\n",
    "\n",
    "df = df[[\"ROAD_TRAFFIC\"]].drop_duplicates()\n",
    "df = df.rename(columns={\"ROAD_TRAFFIC\":\"Address\"})\n",
    "\n",
    "df[\"Address\"] = df[\"Address\"] + \", \" + state_name\n",
    "\n",
    "df[\"lat\"] = 0\n",
    "df[\"lon\"] = 0\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Set up Selenium WebDriver (Make sure you have the appropriate browser driver executable in your PATH)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "for i in tqdm(range(1201,df.shape[0])):\n",
    "\n",
    "    # Example usage\n",
    "    address = df.loc[i,\"Address\"]\n",
    "    # print(address)\n",
    "    updated_url = click_first_result(driver, address)\n",
    "    lat = float(updated_url.split(\"@\")[-1].split(\",\")[0])\n",
    "    lon = float(updated_url.split(\"@\")[-1].split(\",\")[1])\n",
    "\n",
    "    df.loc[i,\"lat\"] = lat\n",
    "    df.loc[i,\"lon\"] = lon\n",
    "\n",
    "    if(i%100 == 0):\n",
    "        df_filter = df.iloc[(int(i/100)-1)*100:i,:]\n",
    "        df_filter.to_csv(path + \"/\" + \"Traffic_Volume/\" + state_name + \"/Coordinates/\" + \"MD_Traffic_Volume_\" + str(int(i/100)) + \".csv\",index=False)\n",
    "\n",
    "\n",
    "df_filter = df.iloc[(int(i/100))*100:i,:]\n",
    "df_filter.to_csv(path + \"/\" + \"Traffic_Volume/\" + state_name + \"/Coordinates\" + \"/MD_Traffic_Volume_\" + str(int(i/100)+1) + \".csv\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "concat_files(path + \"/\" + \"Traffic_Volume/\" + state_name + \"/Coordinates/\", path + \"/\" + \"Traffic_Volume/\" + state_name + \"/\" + state_name + \"_Traffic_Volume.csv\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
