{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------- Importing Libraries -------------#\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from os.path import dirname\n",
    "\n",
    "#--------------- Initializing Parameters ----------#\n",
    "\n",
    "path = dirname(os.getcwd())\n",
    "\n",
    "state_name = \"DE\"\n",
    "\n",
    "\n",
    "def extract_nearest_street(edges_df,lat,lon):\n",
    "    '''\n",
    "    Extract the nodes of the nearest street given a latlong coordinate\n",
    "    Methodology:\n",
    "        Calculate the distance between 2 nodes\n",
    "        Calculate the sum of distances between the point \n",
    "        and two nodes\n",
    "        Extract the nodes/street with the minimum distance\n",
    "    Parameters:\n",
    "        edges_df (dataframe): details of the edges\n",
    "        lat (float): latitude of the point\n",
    "        lon (float): longitude of the point\n",
    "    Returns:\n",
    "        node 1, node 2\n",
    "    '''\n",
    "\n",
    "    edges_df[\"street_dist_node_1\"] = np.sqrt((lon - edges_df[\"node_1_x\"])**2 + (lat - edges_df[\"node_1_y\"])**2)\n",
    "    edges_df[\"street_dist_node_2\"] = np.sqrt((lon - edges_df[\"node_2_x\"])**2 + (lat - edges_df[\"node_2_y\"])**2)\n",
    "\n",
    "    edges_df[\"street_dist_node_1_plus_node_2\"] = edges_df[\"street_dist_node_1\"] + edges_df[\"street_dist_node_2\"]\n",
    "\n",
    "    edges_df[\"street_dist_diff\"] = np.abs(edges_df[\"street_dist_node_1_plus_node_2\"] - edges_df[\"street_dist\"])\n",
    "\n",
    "    min_df = edges_df[edges_df[\"street_dist_diff\"] == edges_df[\"street_dist_diff\"].min()].reset_index(drop=True)\n",
    "\n",
    "    return min_df.loc[0,\"node_1\"],min_df.loc[0,\"node_2\"]\n",
    "\n",
    "\n",
    "def concat_files(path, final_file_name):\n",
    "    '''\n",
    "    Combines all files in a directory and saves it in a single file\n",
    "    Parameters:\n",
    "        path (str): directory where all independent files are saved\n",
    "        final_file_name (str): path of the final file\n",
    "    '''\n",
    "    count = 0\n",
    "    for file_name in os.listdir(path):\n",
    "        try:\n",
    "            df = pd.concat([df,pd.read_csv(path + file_name, low_memory=False)])\n",
    "        except:\n",
    "            df = pd.read_csv(path + file_name, low_memory=False)\n",
    "\n",
    "        count += 1\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    # df = df.rename(columns={\"x\":\"lat\",\"y\":\"lon\",\"X\":\"lat\",\"Y\":\"lon\"})\n",
    "    df.to_csv(final_file_name,index=False)\n",
    "\n",
    "\n",
    "\n",
    "if(state_name == \"MA\"):\n",
    "\n",
    "    # concat_files(path + \"/Traffic_Volume/\" + state_name + \"/County/\",path + \"/Traffic_Volume/\" + state_name + \"/tcds.csv\")\n",
    "\n",
    "    tcds_df = pd.read_csv(path + \"/Traffic_Volume/\" + state_name + \"/tcds.csv\")\n",
    "    growth_df = pd.read_csv(path + \"/Traffic_Volume/\" + state_name + \"/growth_rate.csv\")\n",
    "\n",
    "\n",
    "    tcds_df = tcds_df[~tcds_df[\"Latest\"].isnull()].reset_index(drop=True)\n",
    "    tcds_df[\"Group\"] = tcds_df[\"Rural Urban\"] + tcds_df[\"Functional Class\"].apply(lambda x: x[1])\n",
    "\n",
    "    aadt_df = pd.merge(tcds_df,growth_df,on=[\"Group\"],how=\"left\").drop_duplicates()\n",
    "    aadt_df[\"Year\"] = pd.to_datetime(aadt_df[\"Latest Date\"]).dt.year\n",
    "\n",
    "    for i in range(2002,2023):\n",
    "        aadt_df[\"AADT_\" + str(i)] = 0\n",
    "\n",
    "    for i in tqdm(range(aadt_df.shape[0])):\n",
    "        aadt = aadt_df.loc[i,\"Latest\"]\n",
    "        year = aadt_df.loc[i,\"Year\"]\n",
    "        growth_rate = aadt_df.loc[i,\"Growth_Rate\"]\n",
    "\n",
    "        for year_est in range(2002,2023):\n",
    "            aadt_df.loc[i,\"AADT_\"+str(year_est)] = int(aadt * ((1 + growth_rate) ** (year_est - year)))\n",
    "\n",
    "\n",
    "    aadt_df = aadt_df.rename(columns={\"Latitude\":\"lat\",\"Longitude\":\"lon\"})\n",
    "    aadt_df[\"lat\"] = pd.to_numeric(aadt_df[\"lat\"])\n",
    "    aadt_df[\"lon\"] = pd.to_numeric(aadt_df[\"lon\"])\n",
    "\n",
    "\n",
    "    nodes_df = pd.read_csv(path + \"/Road_Networks/\" + state_name + \"/Road_Network_Nodes_\" + state_name + \".csv\", low_memory=False)\n",
    "    edges_df = pd.read_csv(path + \"/Road_Networks/\" + state_name + \"/Road_Network_Edges_\" + state_name + \".csv\", low_memory=False)\n",
    "\n",
    "    # Merge the latlong coordinates of the nodes of all the edges\n",
    "    edges_df = pd.merge(edges_df,nodes_df,left_on=\"node_1\",right_on=\"node_id\",how=\"left\").drop(columns=[\"node_id\"],axis=1)\n",
    "    edges_df = edges_df.rename(columns={\"x\":\"node_1_x\",\"y\":\"node_1_y\"})\n",
    "\n",
    "    edges_df = pd.merge(edges_df,nodes_df,left_on=\"node_2\",right_on=\"node_id\",how=\"left\").drop(columns=[\"node_id\"],axis=1)\n",
    "    edges_df = edges_df.rename(columns={\"x\":\"node_2_x\",\"y\":\"node_2_y\"})\n",
    "\n",
    "    # Calculate the distance between 2 nodes\n",
    "    edges_df[\"street_dist\"] = np.sqrt((edges_df[\"node_2_x\"] - edges_df[\"node_1_x\"])**2 + (edges_df[\"node_2_y\"] - edges_df[\"node_1_y\"])**2)\n",
    "\n",
    "    aadt_df[\"node_1\"] = 0\n",
    "    aadt_df[\"node_2\"] = 0\n",
    "\n",
    "\n",
    "    for i in tqdm(range(aadt_df.shape[0])):\n",
    "        aadt_df.loc[i,\"node_1\"],aadt_df.loc[i,\"node_2\"] = extract_nearest_street(edges_df,aadt_df.loc[i,\"lat\"],aadt_df.loc[i,\"lon\"])\n",
    "\n",
    "    final_df = pd.DataFrame(columns=[\"node_1\",\"node_2\",\"AADT\",\"year\"])\n",
    "    for year in range(2002,2023):\n",
    "\n",
    "        df = aadt_df[[\"node_1\",\"node_2\",\"AADT_\"+str(year)]].reset_index(drop=True).drop_duplicates()\n",
    "        df[\"year\"] = year\n",
    "        df = df.rename(columns={\"AADT_\"+str(year):\"AADT\"})\n",
    "\n",
    "        final_df = pd.concat([final_df,df])\n",
    "\n",
    "    final_df = final_df.reset_index(drop=True).drop_duplicates()\n",
    "\n",
    "    final_df.to_csv(path + \"/Traffic_Volume/\" + state_name + \"/\" + state_name + \"_AADT.csv\",index=False)\n",
    "\n",
    "if(state_name == \"MD\"):\n",
    "\n",
    "    aadt_df = pd.read_csv(path + \"/Traffic_Volume/\" + state_name + \"/\" + state_name + \"_Traffic_Volume.csv\")\n",
    "\n",
    "    nodes_df = pd.read_csv(path + \"/Road_Networks/\" + state_name + \"/Road_Network_Nodes_\" + state_name + \".csv\", low_memory=False)\n",
    "    edges_df = pd.read_csv(path + \"/Road_Networks/\" + state_name + \"/Road_Network_Edges_\" + state_name + \".csv\", low_memory=False)\n",
    "\n",
    "    # Merge the latlong coordinates of the nodes of all the edges\n",
    "    edges_df = pd.merge(edges_df,nodes_df,left_on=\"node_1\",right_on=\"node_id\",how=\"left\").drop(columns=[\"node_id\"],axis=1)\n",
    "    edges_df = edges_df.rename(columns={\"x\":\"node_1_x\",\"y\":\"node_1_y\"})\n",
    "\n",
    "    edges_df = pd.merge(edges_df,nodes_df,left_on=\"node_2\",right_on=\"node_id\",how=\"left\").drop(columns=[\"node_id\"],axis=1)\n",
    "    edges_df = edges_df.rename(columns={\"x\":\"node_2_x\",\"y\":\"node_2_y\"})\n",
    "\n",
    "    # Calculate the distance between 2 nodes\n",
    "    edges_df[\"street_dist\"] = np.sqrt((edges_df[\"node_2_x\"] - edges_df[\"node_1_x\"])**2 + (edges_df[\"node_2_y\"] - edges_df[\"node_1_y\"])**2)\n",
    "\n",
    "\n",
    "    aadt_df = aadt_df.rename(columns={\"AADT\":\"AADT_2019\"})\n",
    "\n",
    "\n",
    "    aadt_df[\"node_1\"] = 0\n",
    "    aadt_df[\"node_2\"] = 0\n",
    "    for i in tqdm(range(aadt_df.shape[0])):\n",
    "        aadt_df.loc[i,\"node_1\"],aadt_df.loc[i,\"node_2\"] = extract_nearest_street(edges_df,aadt_df.loc[i,\"lat\"],aadt_df.loc[i,\"lon\"])\n",
    "\n",
    "    final_df = pd.DataFrame(columns=[\"node_1\",\"node_2\",\"AADT\",\"year\"])\n",
    "    for year in range(2012,2020):\n",
    "\n",
    "        df = aadt_df[[\"node_1\",\"node_2\",\"AADT_\"+str(year)]].reset_index(drop=True).drop_duplicates()\n",
    "        df[\"year\"] = year\n",
    "        df = df.rename(columns={\"AADT_\"+str(year):\"AADT\"})\n",
    "\n",
    "        final_df = pd.concat([final_df,df])\n",
    "\n",
    "    final_df = final_df.reset_index(drop=True).drop_duplicates()\n",
    "\n",
    "    final_df.to_csv(path + \"/Traffic_Volume/\" + state_name + \"/\" + state_name + \"_AADT.csv\",index=False)\n",
    "\n",
    "if(state_name == \"DE\"):\n",
    "\n",
    "    mapping_df = pd.read_csv(path + \"/Traffic_Volume/\" + state_name + \"/\" + state_name + \"_Road_Coordinate_Mapping.csv\")\n",
    "\n",
    "    nodes_df = pd.read_csv(path + \"/Road_Networks/\" + state_name + \"/Road_Network_Nodes_\" + state_name + \".csv\", low_memory=False)\n",
    "    edges_df = pd.read_csv(path + \"/Road_Networks/\" + state_name + \"/Road_Network_Edges_\" + state_name + \".csv\", low_memory=False)\n",
    "\n",
    "    # Merge the latlong coordinates of the nodes of all the edges\n",
    "    edges_df = pd.merge(edges_df,nodes_df,left_on=\"node_1\",right_on=\"node_id\",how=\"left\").drop(columns=[\"node_id\"],axis=1)\n",
    "    edges_df = edges_df.rename(columns={\"x\":\"node_1_x\",\"y\":\"node_1_y\"})\n",
    "\n",
    "    edges_df = pd.merge(edges_df,nodes_df,left_on=\"node_2\",right_on=\"node_id\",how=\"left\").drop(columns=[\"node_id\"],axis=1)\n",
    "    edges_df = edges_df.rename(columns={\"x\":\"node_2_x\",\"y\":\"node_2_y\"})\n",
    "\n",
    "    # Calculate the distance between 2 nodes\n",
    "    edges_df[\"street_dist\"] = np.sqrt((edges_df[\"node_2_x\"] - edges_df[\"node_1_x\"])**2 + (edges_df[\"node_2_y\"] - edges_df[\"node_1_y\"])**2)\n",
    "\n",
    "\n",
    "    mapping_df[\"node_1\"] = 0\n",
    "    mapping_df[\"node_2\"] = 0\n",
    "    for i in tqdm(range(mapping_df.shape[0])):\n",
    "        mapping_df.loc[i,\"node_1\"],mapping_df.loc[i,\"node_2\"] = extract_nearest_street(edges_df,mapping_df.loc[i,\"lat\"],mapping_df.loc[i,\"lon\"])\n",
    "\n",
    "    aadt_df = pd.read_csv(path + \"/Traffic_Volume/\" + state_name + \"/\" + state_name + \"_AADT_unmapped.csv\")\n",
    "\n",
    "    aadt_df[\"ROAD_TRAFFIC\"] = aadt_df[\"ROAD_TRAFFIC\"] + \", DE\"\n",
    "    aadt_df = aadt_df.rename(columns={\"Year\":\"year\"})\n",
    "\n",
    "    final_df = pd.merge(aadt_df,mapping_df,left_on=[\"ROAD_TRAFFIC\"],right_on=[\"Address\"],how=\"left\")\n",
    "\n",
    "\n",
    "    final_df = final_df[[\"node_1\",\"node_2\",\"AADT\",\"year\"]].reset_index(drop=True).drop_duplicates()\n",
    "\n",
    "\n",
    "    final_df.to_csv(path + \"/Traffic_Volume/\" + state_name + \"/\" + state_name + \"_AADT.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
